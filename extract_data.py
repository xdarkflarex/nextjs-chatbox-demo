"""
Script trÃ­ch xuáº¥t ná»™i dung tá»« Word/Excel sang JSON cho RAG
Cáº§n cÃ i: pip install python-docx openpyxl
"""

import json
import os
from pathlib import Path

try:
    from docx import Document
    from openpyxl import load_workbook
except ImportError:
    print("âŒ Cáº§n cÃ i thÆ° viá»‡n:")
    print("pip install python-docx openpyxl")
    exit(1)

def extract_docx(file_path):
    """TrÃ­ch xuáº¥t text tá»« file Word"""
    doc = Document(file_path)
    content = []
    
    for para in doc.paragraphs:
        text = para.text.strip()
        if text:
            content.append(text)
    
    # TrÃ­ch xuáº¥t tá»« tables
    for table in doc.tables:
        for row in table.rows:
            row_data = [cell.text.strip() for cell in row.cells if cell.text.strip()]
            if row_data:
                content.append(" | ".join(row_data))
    
    return "\n".join(content)

def extract_xlsx(file_path):
    """TrÃ­ch xuáº¥t data tá»« file Excel"""
    wb = load_workbook(file_path, data_only=True)
    content = []
    
    for sheet_name in wb.sheetnames:
        sheet = wb[sheet_name]
        content.append(f"\n=== {sheet_name} ===\n")
        
        for row in sheet.iter_rows(values_only=True):
            row_data = [str(cell) if cell is not None else "" for cell in row]
            row_text = " | ".join([c for c in row_data if c.strip()])
            if row_text.strip():
                content.append(row_text)
    
    return "\n".join(content)

def main():
    data_update_dir = Path("data update")
    output_dir = Path("app/public/data")
    
    if not data_update_dir.exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c: {data_update_dir}")
        return
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Danh sÃ¡ch file cáº§n trÃ­ch xuáº¥t
    files = list(data_update_dir.glob("*.docx")) + list(data_update_dir.glob("*.xlsx"))
    
    if not files:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file Word/Excel trong thÆ° má»¥c 'data update'")
        return
    
    print(f"ğŸ“‚ TÃ¬m tháº¥y {len(files)} file\n")
    
    all_data = []
    
    for file_path in files:
        print(f"ğŸ“„ Äang xá»­ lÃ½: {file_path.name}")
        
        try:
            if file_path.suffix == ".docx":
                content = extract_docx(file_path)
            elif file_path.suffix == ".xlsx":
                content = extract_xlsx(file_path)
            else:
                continue
            
            # Táº¡o entry cho RAG
            entry = {
                "source": file_path.name,
                "type": "document",
                "content": content,
                "metadata": {
                    "filename": file_path.name,
                    "extension": file_path.suffix
                }
            }
            
            all_data.append(entry)
            
            # LÆ°u file riÃªng
            output_file = output_dir / f"{file_path.stem}.txt"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(content)
            
            print(f"   âœ… ÄÃ£ lÆ°u: {output_file.name}")
            print(f"   ğŸ“Š Äá»™ dÃ i: {len(content)} kÃ½ tá»±\n")
            
        except Exception as e:
            print(f"   âŒ Lá»—i: {e}\n")
    
    # LÆ°u táº¥t cáº£ vÃ o 1 file JSON
    output_json = output_dir / "extracted_data.json"
    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(all_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… HoÃ n thÃ nh!")
    print(f"ğŸ“ ÄÃ£ lÆ°u {len(all_data)} file vÃ o: {output_dir}")
    print(f"ğŸ“„ File tá»•ng há»£p: {output_json}")
    
    # Táº¡o file RAG format
    print("\nğŸ“ Táº¡o file RAG format...")
    rag_entries = []
    
    for idx, data in enumerate(all_data, 1):
        # Split content thÃ nh cÃ¡c Ä‘oáº¡n nhá»
        lines = data["content"].split("\n")
        current_chunk = []
        
        for line in lines:
            if line.strip():
                current_chunk.append(line)
                
                # Má»—i chunk ~500 kÃ½ tá»±
                if len("\n".join(current_chunk)) > 500:
                    rag_entry = {
                        "id": f"doc_{idx}_{len(rag_entries)}",
                        "question": "",  # Äá»ƒ trá»‘ng, sáº½ dÃ¹ng cho semantic search
                        "answer": "\n".join(current_chunk),
                        "category": "document",
                        "keywords": [data["source"]],
                        "source": data["source"]
                    }
                    rag_entries.append(rag_entry)
                    current_chunk = []
        
        # Chunk cuá»‘i
        if current_chunk:
            rag_entry = {
                "id": f"doc_{idx}_{len(rag_entries)}",
                "question": "",
                "answer": "\n".join(current_chunk),
                "category": "document",
                "keywords": [data["source"]],
                "source": data["source"]
            }
            rag_entries.append(rag_entry)
    
    # LÆ°u RAG format
    rag_output = output_dir / "rag_documents.json"
    with open(rag_output, "w", encoding="utf-8") as f:
        json.dump(rag_entries, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ÄÃ£ táº¡o {len(rag_entries)} RAG entries")
    print(f"ğŸ“„ File RAG: {rag_output}")
    
    print("\n" + "="*50)
    print("ğŸ¯ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG:")
    print("="*50)
    print("1. File text Ä‘Ã£ trÃ­ch xuáº¥t: app/public/data/*.txt")
    print("2. File JSON tá»•ng há»£p: app/public/data/extracted_data.json")
    print("3. File RAG format: app/public/data/rag_documents.json")
    print("\n4. Äá»ƒ sá»­ dá»¥ng trong API:")
    print("   - Import rag_documents.json vÃ o RAG system")
    print("   - Hoáº·c merge vá»›i rag_all.json hiá»‡n cÃ³")
    print("\n5. Test:")
    print("   python test_rag.py")

if __name__ == "__main__":
    main()
